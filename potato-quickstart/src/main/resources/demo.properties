################################################################
# 注意！所有非 spark. 前缀的参数，均不会被SparkConf加载。           #
# 如需添加自定义参数后在程序中调用，请注意此规则。                    #
################################################################
#
#
################################################################
# potato config                                                #
################################################################
# spark-submit脚本，用于在某些集群中区别spark1和spark2，比如cdh。
spark.potato.submit.bin=spark2-submit
# todo 主类入口。
spark.potato.main.class=spark.streaming.potato.core.template.GeneralTemplate
spark.potato.main.jar=potato-quickstart-0.0.1-SNAPSHOT.jar
# todo 窗口滑动时间。
spark.potato.streaming.slide.duration.seconds=10
## running lock config
# 是否启用执行锁，启用此参数，只有获取锁的作业可以正常执行，否则在尝试
# 超时后自动停止。
spark.potato.running.lock.enable=true
# 尝试时间 * 尝试次数建议大于heartbeat超时时间，避免旧作业出现问题，但是
# 在心跳未超时时，新作业提前报错终止。
spark.potato.running.lock.try.max=5
spark.potato.running.lock.try.interval.ms=30000
# 是否强制获取锁，开启此参数，新提交作业会强制清除旧锁，导致旧作业停止。
spark.potato.running.lock.force=true
spark.potato.running.lock.heartbeat.interval.ms=10000
spark.potato.running.lock.heartbeat.timeout.ms=90000
# 锁实现类，目前仅支持zookeeper。
spark.potato.running.lock.type=zookeeper
spark.potato.running.lock.zookeeper.addr=test01:2181,test02:2181,test03:2181
# zookeeper中用于存放锁的路径，锁名称为 ${app.name}.lock 。
spark.potato.running.lock.zookeeper.path=/potato/lock/test
#
#
################################################################
# spark config                                                 #
################################################################
# todo 作业名称，用于运行锁的标识，必须唯一。
spark.app.name=potato_config_demo
spark.master=yarn
spark.submit.deployMode=cluster
spark.driver.cores=1
spark.driver.memory=512m
spark.executor.cores=2
spark.executor.memory=512m
## 作业调度方式，支持 FIFO(默认) 和 FAIR 。
# spark.scheduler.mode=FIFO
## 启用dynamicAllocation。
spark.shuffle.service.enabled=true
spark.dynamicAllocation.enabled=true
spark.dynamicAllocation.executorIdleTimeout=60s
spark.dynamicAllocation.cachedExecutorIdleTimeout=1h
spark.dynamicAllocation.initialExecutors=1
spark.dynamicAllocation.maxExecutors=2
spark.dynamicAllocation.minExecutors=1
spark.dynamicAllocation.schedulerBacklogTimeout=5s
spark.dynamicAllocation.sustainedSchedulerBacklogTimeout=5s
## 仅在staticAllocation模式生效。
# spark.executor.instances=2
## classpath参数，仅在cluster模式生效。
spark.driver.userClassPathFirst=false
spark.executor.userClassPathFirst=false
## 开启背压。
spark.streaming.backpressure.enabled=true
#spark.streaming.backpressure.initialRate
#spark.streaming.stopGracefullyOnShutdown
#spark.streaming.kafka.maxRatePerPartition=1000
#spark.streaming.kafka.maxRetries=1
#
#
################################################################
# yarn config                                                  #
################################################################
## am参数，仅在yarn-client模式生效。
# spark.yarn.am.memory=1024m
# spark.yarn.am.cores=1
# spark.yarn.am.waitTime=120s
# spark.yarn.am.memoryOverhead=1024m
spark.yarn.driver.memoryOverhead=512m
spark.yarn.executor.memoryOverhead=512m
spark.yarn.queue=default
spark.yarn.submit.waitAppCompletion=false
#
#
################################################################
# monitor config                                               #
################################################################
## backlog monitor 监控批次延迟时间。
spark.potato.monitor.backlog.enable=true
# 批次延时阈值。
spark.potato.monitor.backlog.delay.sec=30
# 告警最大告警次数。
spark.potato.monitor.backlog.reporter.max=3
# 告警间隔描述。
spark.potato.monitor.backlog.reporter.interval.sec=300
# 告警类型，目前支持方式为ding(钉钉机器人)。
spark.potato.monitor.backlog.reporter.type=ding
spark.potato.monitor.backlog.reporter.ding.token=xxxx
spark.potato.monitor.backlog.reporter.ding.atall=true
spark.potato.monitor.backlog.reporter.ding.atphones=130xxxxxxxx,131xxxxxxxx
#
################################################################
# plugins config                                               #
################################################################
## hbase plugin，所有参数在去除spark.potato.hbase.site.前缀后加载进Configuration。
spark.potato.hbase.site.hbase.zookeeper.quorum=test01,test02
spark.potato.hbase.site.hbase.zookeeper.property.clientPort=2181
#
################################################################
# source config                                                #
################################################################
## kafka source
# offsets存储方式，支持zookeeper、kafka两种kafka内部存储，与hbas 外部存储。
spark.potato.source.kafka.offsets.storage=hbase
# hbase offset 外部存储参数。hbase表必须预创建。
# 存储规则: key -> ${group}##${topic}, column -> partition:${partition}。
spark.potato.source.kafka.offsets.storage.hbase.table=kafka_offsets_storage
spark.potato.source.kafka.offsets.storage.hbase.conf.hbase.zookeeper.quorum=test01,test02
spark.potato.source.kafka.offsets.storage.hbase.conf.hbase.zookeeper.property.clientPort=2181
# 订阅topic，多个topic逗号隔开。
spark.potato.source.kafka.subscribe.topics=test1,test2
# 是否在每批次执行完毕后提交offset。
spark.potato.source.kafka.offsets.auto.update=true
# 在提交offset时的延后时间，单位ms，计划用于窗口模式，该功能未在窗口模式下测试。
#spark.potato.source.kafka.offsets.auto.update.delay=0
# consumer参数，所有参数在去除前缀后将用于KafkaUtils.createDirectStream方法。
# todo 重要参数！存储kafka的groupId，必须唯一。
spark.potato.source.kafka.consumer.group.id=test_group
spark.potato.source.kafka.consumer.bootstrap.servers=test01:9092,test02:9092
spark.potato.source.kafka.consumer.auto.offset.reset=earliest
#
#
################################################################
# sink config                                                  #
################################################################
# kafka sink 去除spark.potato.sink.kafka.producer前缀后加入producer参数。
spark.potato.sink.kafka.producer.bootstrap.servers=test01:9092,test02:9092
spark.potato.sink.kafka.producer.acks=all
spark.potato.sink.kafka.producer.retries=1
spark.potato.sink.kafka.producer.batch.size=16384
spark.potato.sink.kafka.producer.linger.ms=1
spark.potato.sink.kafka.producer.buffer.memory=33554432
spark.potato.sink.kafka.producer.key.serializer=org.apache.kafka.common.serialization.StringSerializer
spark.potato.sink.kafka.producer.value.serializer=org.apache.kafka.common.serialization.StringSerializer
