################################################################
# 注意！所有非 spark. 前缀的参数，均不会被SparkConf加载。           #
# 如需添加自定义参数后在程序中调用，请注意此规则。                    #
################################################################
#
#
################################################################
# potato common config                                         #
################################################################
# 钉钉机器人token。
spark.potato.common.sender.ding.token=abc
# 钉钉机器人at人员，支持all/none/phone1,phone2。
spark.potato.common.sender.ding.at=none
################################################################
# potato spark config                                         #
################################################################
# 作业名称。
spark.app.name=StreamingDemoTest
# 指向提交作业使用的主类。
spark.potato.main.class=quickstart.streaming.StreamingDemo
spark.potato.main.jar=potato-quickstart-0.2.0-SNAPSHOT.jar
# streaming context批处理时间。
spark.potato.spark.streaming.batch.duration.ms=5000
# 需要开启附加服务，配置值为服务名称，如不开启附加服务，请删除此参数或配置为'false'
spark.potato.spark.additional.services=StreamingSingletonLock,StreamingBacklogMonitor
# 需要开启自定义服务，配置值为类全限定名，如不开启附加服务，请删除此参数或配置为'false'
#spark.potato.spark.custom.services.class=class.of.A,class.of.B
### 锁配置。
# 获取锁最大重试次数。
spark.potato.lock.singleton.try.max=3
# 获取锁重试间隔。
spark.potato.lock.singleton.try.interval.ms=30000
# 是否强制获取锁，如配置true，则会清楚旧锁。
spark.potato.lock.singleton.force=true
# 锁心跳间隔。
spark.potato.lock.singleton.heartbeat.interval.ms=10000
# 锁心跳超时时间。
spark.potato.lock.singleton.heartbeat.timeout.ms=90000
# 锁存储类型。
spark.potato.lock.singleton.type=zookeeper
# zookeeper锁地址。
spark.potato.lock.singleton.zookeeper.quorum=test01:2181
# zookeeper锁路径。
spark.potato.lock.singleton.zookeeper.path=/potato/spark/lock/singleton
### 监控配置。
# 批次积压告警阈值。
spark.potato.spark.monitor.streaming.backlog.threshold.ms=60000
# 批次积压告警间隔。
spark.potato.spark.monitor.streaming.backlog.report.interval.ms=600000
# 批次积压告警最大次数。
spark.potato.spark.monitor.streaming.backlog.report.max=3
# 批次积压告警类型。
spark.potato.spark.monitor.streaming.backlog.report.sender=ding
################################################################
# potato spark resource config                                 #
################################################################
spark.master=yarn
spark.submit.deployMode=cluster
spark.driver.cores=1
spark.driver.memory=512m
spark.executor.cores=2
spark.executor.memory=512m
## 启用dynamicAllocation。
spark.shuffle.service.enabled=true
spark.dynamicAllocation.enabled=true
spark.dynamicAllocation.executorIdleTimeout=60s
spark.dynamicAllocation.cachedExecutorIdleTimeout=1h
spark.dynamicAllocation.initialExecutors=1
spark.dynamicAllocation.maxExecutors=2
spark.dynamicAllocation.minExecutors=1
spark.dynamicAllocation.schedulerBacklogTimeout=5s
spark.dynamicAllocation.sustainedSchedulerBacklogTimeout=5s
## 仅在staticAllocation模式生效。
# spark.executor.instances=2
## classpath参数，仅在cluster模式生效。
spark.driver.userClassPathFirst=false
spark.executor.userClassPathFirst=false
## receiver背压。在kafka源下不生效。
#spark.streaming.backpressure.enabled=true
#spark.streaming.backpressure.initialRate
#spark.streaming.stopGracefullyOnShutdown
spark.yarn.driver.memoryOverhead=512m
spark.yarn.executor.memoryOverhead=512m
spark.yarn.queue=default
spark.yarn.submit.waitAppCompletion=false