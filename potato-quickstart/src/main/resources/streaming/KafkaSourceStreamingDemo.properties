################################################################
# 注意！所有非 spark. 前缀的参数，均不会被SparkConf加载。           #
# 如需添加自定义参数后在程序中调用，请注意此规则。                    #
################################################################
#
#
################################################################
# potato submit config                                         #
################################################################
# spark-submit脚本，用于在某些集群中区别spark1和spark2，比如cdh。
spark.potato.submit.bin=spark2-submit
# todo 重要参数！主类入口。
spark.potato.submit.main.class=spark.potato.quickstart.streaming.KafkaSourceStreamingDemo
spark.potato.submit.main.jar=potato-quickstart-0.1.1-SNAPSHOT.jar
#
#
################################################################
# spark config                                                 #
################################################################
# todo 重要参数！作业名称，用于运行锁的标识，必须唯一。
spark.app.name=KafkaSourceStreamingDemo
spark.master=yarn
spark.submit.deployMode=cluster
spark.driver.cores=1
spark.driver.memory=512m
spark.executor.cores=2
spark.executor.memory=512m
## 作业调度方式，支持 FIFO(默认) 和 FAIR 。
# spark.scheduler.mode=FIFO
## 启用dynamicAllocation。
spark.shuffle.service.enabled=true
spark.dynamicAllocation.enabled=true
spark.dynamicAllocation.executorIdleTimeout=60s
spark.dynamicAllocation.cachedExecutorIdleTimeout=1h
spark.dynamicAllocation.initialExecutors=1
spark.dynamicAllocation.maxExecutors=2
spark.dynamicAllocation.minExecutors=1
spark.dynamicAllocation.schedulerBacklogTimeout=5s
spark.dynamicAllocation.sustainedSchedulerBacklogTimeout=5s
## 仅在staticAllocation模式生效。
# spark.executor.instances=2
## classpath参数，仅在cluster模式生效。
spark.driver.userClassPathFirst=false
spark.executor.userClassPathFirst=false
## 开启背压。
spark.streaming.backpressure.enabled=true
#spark.streaming.backpressure.initialRate
#spark.streaming.stopGracefullyOnShutdown
#spark.streaming.kafka.maxRatePerPartition=1000
#spark.streaming.kafka.maxRetries=1
#
#
################################################################
# yarn config                                                  #
################################################################
spark.yarn.driver.memoryOverhead=512m
spark.yarn.executor.memoryOverhead=512m
spark.yarn.queue=default
spark.yarn.submit.waitAppCompletion=false
#
#
################################################################
# potato common config                                         #
################################################################
# todo 重要参数！streaming context批处理时间。
spark.potato.common.streaming.batch.duration.ms=5000
# 需要开启附加服务，配置值为服务名称，如不开启附加服务，请删除此参数或配置为'false'
spark.potato.common.additional.services=StreamingRunningLock,StreamingBacklogMonitor
# 需要开启自定义服务，配置值为类全限定名，如不开启附加服务，请删除此参数或配置为'false'
spark.potato.common.custom.services.class=false
#
#
################################################################
# potato hbase config                                         #
################################################################
# hbase zookeeper 地址。
spark.potato.hbase.conf.hbase.zookeeper.quorum=localhost
# hbase zookeeper 端口。
spark.potato.hbase.conf.hbase.zookeeper.property.clientPort=2181
#
#
################################################################
# potato kafka config                                         #
################################################################
# kafka consumer 参数。
# todo 重要参数！存储kafka的groupId，必须唯一。
spark.potato.kafka.consumer.conf.group.id=KafkaSourceStreamingDemo_group
spark.potato.kafka.consumer.conf.auto.offset.reset=largest
spark.potato.kafka.consumer.conf.bootstrap.servers=test01:9092
# kafka producer 参数。
spark.potato.kafka.producer.conf.bootstrap.servers=test01:9092
spark.potato.kafka.producer.conf.key.serializer=org.apache.kafka.common.serialization.StringSerializer
spark.potato.kafka.producer.conf.value.serializer=org.apache.kafka.common.serialization.StringSerializer
# kafka source 订阅topic。
spark.potato.kafka.source.subscribe.topics=test1,test2
# offsets 存储类型。
spark.potato.kafka.offsets.storage=kafka
# offsets是否自动提交。
spark.potato.kafka.offsets.auto.update=true
# offsets自动提交延迟。
spark.potato.kafka.offsets.auto.update.delay=0
# hbase offsets存储表名。
spark.potato.kafka.offsets.storage.hbase.table=kafka_offsets_storage
# hbase offsets存储列族。
spark.potato.kafka.offsets.storage.hbase.family=partition
# hbase offsets地址参数。
spark.potato.kafka.offsets.storage.hbase.conf.hbase.zookeeper.quorum=test01
spark.potato.kafka.offsets.storage.hbase.conf.hbase.zookeeper.property.clientPort=2181
#
#
################################################################
# potato lock config                                           #
################################################################
# 获取锁最大重试次数。
spark.potato.lock.singleton.try.max=3
# 获取锁重试间隔。
spark.potato.lock.singleton.try.interval.ms=30000
# 是否强制获取锁，如配置true，则会清楚旧锁。
spark.potato.lock.singleton.force=true
# 锁心跳间隔。
spark.potato.lock.singleton.heartbeat.interval.ms=10000
# 锁心跳超时时间。
spark.potato.lock.singleton.heartbeat.timeout.ms=90000
# 锁存储类型。
spark.potato.lock.singleton.type=zookeeper
# zookeeper锁地址。
spark.potato.lock.singleton.zookeeper.quorum=test01:2181
# zookeeper锁路径。
spark.potato.lock.singleton.zookeeper.path=/potato/lock/singleton
#
#
################################################################
# potato monitor config                                        #
################################################################
# 批次积压告警阈值。
spark.potato.monitor.backlog.threshold.ms=60000
# 批次积压告警间隔。
spark.potato.monitor.backlog.reporter.interval.ms=600000
# 批次积压告警最大次数。
spark.potato.monitor.backlog.reporter.max=3
# 批次积压告警类型。
spark.potato.monitor.backlog.notify.type=ding
# 钉钉告警token。
spark.potato.monitor.backlog.notify.ding.token=xxx
# 钉钉告警是否at所有人。
spark.potato.monitor.backlog.notify.ding.at.all=false
# 钉钉告警需要at的手机号列表。
spark.potato.monitor.backlog.notify.ding.at.phones=123,456

