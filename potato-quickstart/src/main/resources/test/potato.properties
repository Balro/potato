########
# 注意！所有非 spark. 前缀的参数，均不会被SparkConf加载。
# 如需添加自定义参数后在程序中调用，请注意此规则。
########
########
# potato config
########
spark.potato.submit.bin=spark2-submit
spark.potato.main.class=spark.streaming.potato.quickstart.KafkaDemo
spark.potato.main.jar=potato-quickstart-0.0.1-SNAPSHOT.jar
spark.potato.streaming.slide.duration.seconds=10
#
########
# deploy config
########
spark.app.name=potato-quickstart
spark.master=yarn
spark.submit.deployMode=cluster
## 仅在staticAllocation模式生效。
# spark.executor.instances=2
spark.driver.cores=1
spark.driver.memory=512m
spark.executor.cores=2
spark.executor.memory=512m
#spark.default.parallelism
## 启用dynamicAllocation。
spark.shuffle.service.enabled=true
spark.dynamicAllocation.enabled=true
spark.dynamicAllocation.executorIdleTimeout=60s
spark.dynamicAllocation.cachedExecutorIdleTimeout=1h
spark.dynamicAllocation.initialExecutors=1
spark.dynamicAllocation.maxExecutors=8
spark.dynamicAllocation.minExecutors=1
spark.dynamicAllocation.schedulerBacklogTimeout=5s
spark.dynamicAllocation.sustainedSchedulerBacklogTimeout=5s
## classpath参数，仅在cluster模式生效。
spark.driver.userClassPathFirst=false
spark.executor.userClassPathFirst=false
#
#### yarn config
## am参数，仅在yarn-client模式生效。
# spark.yarn.am.memory=1024m
# spark.yarn.am.cores=1
# spark.yarn.am.waitTime=120s
# spark.yarn.am.memoryOverhead=1024m
spark.yarn.driver.memoryOverhead=512m
spark.yarn.executor.memoryOverhead=512m
spark.yarn.queue=default
spark.yarn.submit.waitAppCompletion=false
#
########
# monitor config
########
########
# source config
########
########
########
# sink config
########